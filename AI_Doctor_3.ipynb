{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilaltaf/ai-doctor-3-finetune-deepseekr1/blob/main/AI_Doctor_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cZvRdTq-i88",
        "outputId": "6ee027e3-cc3b-4567-8706-4ad5462f80c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Video of Fine tuning\n"
          ]
        }
      ],
      "source": [
        "print(\"First Video of Fine tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GspF8nVw-dt5"
      },
      "outputs": [],
      "source": [
        "# Step1: Create & Setup hugging face API token in Collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z87270vtsVl7",
        "outputId": "1f00448a-9e06-4da0-a056-6b1cdf8c2e20",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.12/dist-packages (2025.8.10)\n",
            "Collecting git+https://github.com/unslothai/unsloth.git\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-w4nvkjm5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-w4nvkjm5\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 1748e4794b2fcef03cb2ec9e0a325692e3b771cd\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.8.10-py3-none-any.whl size=313333 sha256=2b379784fcd1e7ea5e7c7d92708d6354ba0f05125757407c80dc0a598276528d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s_6yo1qo/wheels/60/3e/1f/e576c07051d90cf64b6a41434d87ccf4db33fafd5343bf5de0\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth\n",
            "  Attempting uninstall: unsloth\n",
            "    Found existing installation: unsloth 2025.8.10\n",
            "    Uninstalling unsloth-2025.8.10:\n",
            "      Successfully uninstalled unsloth-2025.8.10\n",
            "Successfully installed unsloth-2025.8.10\n"
          ]
        }
      ],
      "source": [
        "!pip install unsloth # install unsloth\n",
        "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # Also get the latest version Unsloth!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y unsloth unsloth-zoo\n",
        "!pip install --no-cache-dir \"unsloth[all]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "TC9qZNROecAS",
        "outputId": "dfa20fa7-7a7e-4ea6-ba82-7fb4b814c972"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: unsloth 2025.8.10\n",
            "Uninstalling unsloth-2025.8.10:\n",
            "  Successfully uninstalled unsloth-2025.8.10\n",
            "Found existing installation: unsloth_zoo 2025.8.8\n",
            "Uninstalling unsloth_zoo-2025.8.8:\n",
            "  Successfully uninstalled unsloth_zoo-2025.8.8\n",
            "Collecting unsloth[all]\n",
            "  Downloading unsloth-2025.8.9-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: unsloth 2025.8.9 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting unsloth_zoo>=2025.8.8 (from unsloth[all])\n",
            "  Downloading unsloth_zoo-2025.8.8-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (2.8.0+cu126)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.0.32.post2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.47.0)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (25.0)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.9.29)\n",
            "Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (4.55.4)\n",
            "Requirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (1.10.1)\n",
            "Requirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.21.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.17.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.34.4)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.35.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth[all]) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[all]) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth[all]) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[all]) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[all]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[all]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[all]) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[all]) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[all]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth[all]) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[all]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth[all]) (1.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth[all]) (1.11.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth[all]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth[all]) (0.21.4)\n",
            "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.8->unsloth[all]) (0.10.0)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.8->unsloth[all]) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.8->unsloth[all]) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.8->unsloth[all]) (0.19.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth[all]) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[all]) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[all]) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[all]) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth[all]) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth[all]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth[all]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth[all]) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[all]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth[all]) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth[all]) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth[all]) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth[all]) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth[all]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth[all]) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth[all]) (1.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[all]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth[all]) (1.17.0)\n",
            "Downloading unsloth_zoo-2025.8.8-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.8/184.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth-2025.8.9-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m224.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unsloth_zoo, unsloth\n",
            "Successfully installed unsloth-2025.8.9 unsloth_zoo-2025.8.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "unsloth_zoo"
                ]
              },
              "id": "e4e2a2e487884def858c211d5b206323"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w5Z3IRI5Ciz",
        "outputId": "1af620e2-69f8-43b9-c1f0-474c8f7b9f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "# Step3: Import necessary libraries\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from unsloth import is_bfloat16_supported\n",
        "from huggingface_hub import login\n",
        "from transformers import TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fnNkaxSa5EG8"
      },
      "outputs": [],
      "source": [
        "# Step4: Check HF token\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbMzRW7Q-rI1",
        "outputId": "60aac0bd-dc20-4ad2-bcc0-a9e513c67aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Optional: Check GPU availability\n",
        "# Test if CUDA is available\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9uJ0kyU5EJC",
        "outputId": "7cacf37e-66d5-481f-9a9d-2989fffa4139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.8.9: Fast Llama patching. Transformers: 4.55.4.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "# Step5: Setup pretrained DeepSeek-R1\n",
        "\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "max_sequence_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ywwTJ-EX-wZS"
      },
      "outputs": [],
      "source": [
        "# Step6: Setup system prompt\n",
        "prompt_style = \"\"\"\n",
        "Below is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\n",
        "\n",
        "Before crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\n",
        "\n",
        "### Task:\n",
        "You are a medical expert specializing in clinical reasoning, diagnostics, and treatment planning. Answer the medical question below using your advanced knowledge.\n",
        "\n",
        "### Query:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "<think>{}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXlU4R1M-x9T"
      },
      "outputs": [],
      "source": [
        "# Step7: Run Inference on the model\n",
        "\n",
        "# Define a test question\n",
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or\n",
        "              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQRw7EOj-x_Y"
      },
      "outputs": [],
      "source": [
        "print(response[0].split(\"### Answer:\")[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1rGOKPF-yB1"
      },
      "outputs": [],
      "source": [
        "# Step8: Setup fine-tuning\n",
        "\n",
        "# Load Dataset\n",
        "medical_dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split = \"train[:500]\", trust_remote_code = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGxWOJVn-yD7"
      },
      "outputs": [],
      "source": [
        "medical_dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRtCjhOZ-yGS"
      },
      "outputs": [],
      "source": [
        "EOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which tells the model when to stop generating text during training\n",
        "EOS_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHVFpt51862S"
      },
      "outputs": [],
      "source": [
        "### Finetuning\n",
        "# Updated training prompt style to add </think> tag\n",
        "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning.\n",
        "Please answer the following medical question.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "{}\"\"\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrKFL1ec87CP"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for fine-tuning\n",
        "\n",
        "def preprocess_input_data(examples):\n",
        "  inputs = examples[\"Question\"]\n",
        "  cots = examples[\"Complex_CoT\"]\n",
        "  outputs = examples[\"Response\"]\n",
        "\n",
        "  texts = []\n",
        "\n",
        "  for input, cot, output in zip(inputs, cots, outputs):\n",
        "    text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "    texts.append(text)\n",
        "\n",
        "  return {\n",
        "      \"texts\" : texts,\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTsrjryT_RLF"
      },
      "outputs": [],
      "source": [
        "finetune_dataset = medical_dataset.map(preprocess_input_data, batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crLgEm6h9BNB"
      },
      "outputs": [],
      "source": [
        "finetune_dataset[\"texts\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p32ium159BPF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyLZqq8R5ELJ"
      },
      "outputs": [],
      "source": [
        "# Step9: Setup/Apply LoRA finetuning to the model\n",
        "\n",
        "model_lora = FastLanguageModel.get_peft_model(\n",
        "    model = model,\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3047,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_1xufC2Yt3K"
      },
      "outputs": [],
      "source": [
        "# Add this before creating the trainer\n",
        "if hasattr(model, '_unwrapped_old_generate'):\n",
        "    del model._unwrapped_old_generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NenTCAT45ENx"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model_lora,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = finetune_dataset,\n",
        "    dataset_text_field = \"texts\",\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dataset_num_proc = 1,\n",
        "\n",
        "    # Define training args\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        num_train_epochs = 1,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST9J4i8PZjYy"
      },
      "outputs": [],
      "source": [
        "# Setup WANDB\n",
        "from google.colab import userdata\n",
        "wnb_token = userdata.get(\"WANDB_API_TOKEN\")\n",
        "# Login to WnB\n",
        "wandb.login(key=wnb_token) # import wandb\n",
        "run = wandb.init(\n",
        "    project='Fine-tune-DeepSeek-R1-on-Medical-CoT-Dataset',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irR021n75EP4"
      },
      "outputs": [],
      "source": [
        "# Start the fine-tuning process\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwTqmIfz_uNd"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofzlf5UlfP3o"
      },
      "outputs": [],
      "source": [
        "# Step10: Testing after fine-tuning\n",
        "question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing\n",
        "              but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings,\n",
        "              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model_lora.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jhG3-7Lf-ej"
      },
      "outputs": [],
      "source": [
        "print(response[0].split(\"### Answer:\")[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDlOpre6gTln"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"A 59-year-old man presents with a fever, chills, night sweats, and generalized fatigue,\n",
        "              and is found to have a 12 mm vegetation on the aortic valve. Blood cultures indicate gram-positive, catalase-negative,\n",
        "              gamma-hemolytic cocci in chains that do not grow in a 6.5% NaCl medium.\n",
        "              What is the most likely predisposing factor for this patient's condition?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate a response\n",
        "outputs = model_lora.generate (\n",
        "    input_ids = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask,\n",
        "    max_new_tokens = 1200,\n",
        "    use_cache = True\n",
        ")\n",
        "\n",
        "# Decode the response tokens back to text\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "\n",
        "print(response[0].split(\"### Answer:\")[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8cpFyM2gTRE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkn0oZJdfP6H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8eKO6AXfP8x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVnWnMB1fP_C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qqDPOZvfQBN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b06cbe0f"
      },
      "source": [
        "!pip install unsloth_zoo"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}